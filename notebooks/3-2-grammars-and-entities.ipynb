{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-2 Grammars & Entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports, Custom Function, Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Off there to the right -- somewhere -- is a large\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "\n",
    "# Improved normalization function\n",
    "# Removes all punctuation except periods (for sentences)\n",
    "# Lowercases all words and tokenizes\n",
    "def tknize (a_string):\n",
    "    # Handle all the string operations at one time\n",
    "    clean = re.sub('[^a-zA-Z \\.]', ' ', a_string).lower()\n",
    "    # Create the list of sub-strings (tokens) and return it\n",
    "    return nltk.tokenize.word_tokenize(clean)\n",
    "\n",
    "# DATA\n",
    "with open(\"../data/mdg.txt\", mode=\"r\", encoding=\"utf-8\") as f:\n",
    "            mdg = f.read()\n",
    "\n",
    "print(mdg[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['off', 'there', 'to', 'the', 'right', 'somewhere', 'is', 'a', 'large', 'island']\n"
     ]
    }
   ],
   "source": [
    "# Break them into a list of tokens\n",
    "mdg_ = tknize(mdg)\n",
    "\n",
    "print(mdg_[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing\n",
    "\n",
    "See the [list of PoS tags](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html) on the UPenn website for details on tags. For a complete list, run the following: `nltk.help.upenn_tagset()` -- please make sure you download the tag set first, `nltk.download(\"tagsets\")`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('off', 'RB'),\n",
       " ('there', 'EX'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('right', 'NN'),\n",
       " ('somewhere', 'RB'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('large', 'JJ'),\n",
       " ('island', 'NN')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mdg_ is our cleaned list of tokens which keeps only periods.\n",
    "mdg_tagged = nltk.pos_tag(mdg_)\n",
    "\n",
    "mdg_tagged[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUIZ: Describe the data structure above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "off there to the right somewhere is a large island\n"
     ]
    }
   ],
   "source": [
    "# You can re-assemble this to see what the parser is going to see\n",
    "reassembled = [tagged[0] for tagged in mdg_tagged[0:10]]\n",
    "print(\" \".join(reassembled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of the code block above is to demonstrate that the tagged document is simply a list of tuples, which you can manipulate a number of ways, here I am simply grabbing the first value in the tuple, `tuple[0]`. \n",
    "\n",
    "We could also do something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "large\n",
      "rainsford\n",
      "old\n",
      "ship\n",
      "trap\n",
      "suggestive\n",
      "curious\n",
      "i\n",
      "dank\n",
      "tropical\n",
      "palpable\n",
      "thick\n",
      "warm\n",
      "good\n"
     ]
    }
   ],
   "source": [
    "for t in mdg_tagged[0:100]:\n",
    "    if t[1] == 'JJ':\n",
    "        print(t[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Uh oh!*** NLTK isn't infallible! The NLTK has tagged \"rainsford\" and \"i\" as adjectives. (Tagging the \"I\" as an adjective is something I have encountered before.) First, you should know there are alternatives to NLTK -- I recommend spaCy over TextBlob -- but you also have to determine if these are one-off errors that you can ignore or if you can ignore these errors because of the scale of your work. This is an analytical judgment call: you must make it for yourself, but you must **document** it for others. *Documentation makes **you** look smart!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "large island\n",
      "old charts\n",
      "ship trap island whitney\n",
      "suggestive name isn t\n",
      "curious dread\n",
      "i don t\n",
      "dank tropical night\n",
      "warm blackness\n",
      "ve good eyes\n",
      "i ve\n"
     ]
    }
   ],
   "source": [
    "# Get the functionality we need\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Create the blob\n",
    "blob = TextBlob(re.sub('[^a-zA-Z \\.]', ' ', mdg).lower())\n",
    "\n",
    "# Get the noun phrases (so easy!)\n",
    "mdg_np = blob.noun_phrases\n",
    "\n",
    "# See some results\n",
    "for i in mdg_np[0:10]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Lions, tigers, and bear! Oh my!*** TextBlob produces weird results as well. This is not easy! (Think about the implications for large language models and how many inaccurate results are being \"averaged\" out.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Apple PROPN NNP\n",
      "is be AUX VBZ\n",
      "looking look VERB VBG\n",
      "at at ADP IN\n",
      "buying buy VERB VBG\n",
      "U.K. U.K. PROPN NNP\n",
      "startup startup VERB VBD\n",
      "for for ADP IN\n",
      "$ $ SYM $\n",
      "1 1 NUM CD\n",
      "billion billion NUM CD\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" PUNCT\n",
      "Off ADV\n",
      "there ADV\n",
      "to ADP\n",
      "the DET\n",
      "right NOUN\n",
      "-- PUNCT\n",
      "somewhere ADV\n",
      "-- PUNCT\n",
      "is AUX\n"
     ]
    }
   ],
   "source": [
    "mdg_doc = nlp(mdg)\n",
    "\n",
    "for token in mdg_doc[0:10]:\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'London', 'Puritan', 'liqueur', 'Ugh', 'Swamp', 'Death', 'East', 'weary', 'borsch', 'Aurelius', 'astrakhan', 'Pol', 'Doubtless', 'Purdey', 'City', 'Rains', 'revoir', 'Watch', 'Great', 'Mr.', 'Malacca', 'Sanger', 'jut', 'Laughter', 'Uganda', 'gray', 'Americans', 'Cliquot', 'Tibet', 'Splendid', 'Marcus', 'God', 'Lucar', 'Folies', 'Pistol', 'bush', 'Gasping', 'Guns', 'Rainsford', 'Boredom', 'San', 'Carlo', 'General', 'Chambertin', 'Amazon', 'Sleep', 'Sea', 'Veuve', 'Bah', 'Cossack', 'French', 'Trap', 'Ivan', 'America', 'Russian', 'Ganges', 'I.', 'Zaroff', 'Caucasus', '.the', 'Russians', 'ford', 'Providence', 'Monte', \"anything?'--\", 'York', 'huskily', 'Africa', 'Butterfly', 'cr^epes', 'Bergere', 'Nielsen', 'bay', 'china', 'Island', 'general', 'Whitney', 'Captain', 'Roger', 'Swam', 'Dusk', 'English', 'Ship', 'Chablis', 'Lazarus', 'Moscow', 'Swede', 'au', 'American', 'New', 'Czar', 'Madame', 'Russia', 'khaki', 'White', 'staccato', 'Cape', 'Chinese', 'Mirage', 'Automatically', 'Suzette', 'nearer', 'Crimea', 'France', 'Paris', 'Caribbean', 'Ennui', 'Rio', 'Au'}\n"
     ]
    }
   ],
   "source": [
    "mdg_PPNs = []\n",
    "for token in mdg_doc:\n",
    "    if token.pos_ == \"PROPN\":\n",
    "        mdg_PPNs.append(token.text)\n",
    "\n",
    "print(set(mdg_PPNs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.the', 'rainsford', 'rainsford', 'rainsford', 'general', 'rainsford']\n"
     ]
    }
   ],
   "source": [
    "# Compare NLTK and Spacy on proper nouns\n",
    "mdg_PPNs_nltk = []\n",
    "for token in mdg_tagged:\n",
    "    if token[1] == \"NNP\":\n",
    "        mdg_PPNs_nltk.append(token[0])\n",
    "\n",
    "print(mdg_PPNs_nltk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('off', 'RB')\n",
      "('there', 'EX')\n",
      "('to', 'TO')\n",
      "(NP the/DT right/NN)\n",
      "('somewhere', 'RB')\n",
      "('is', 'VBZ')\n",
      "(NP a/DT large/JJ island/NN)\n",
      "('said', 'VBD')\n",
      "(NP whitney/NN)\n",
      "('.', '.')\n",
      "('it', 'PRP')\n",
      "('s', 'VBZ')\n",
      "('rather', 'RB')\n",
      "(NP a/DT mystery/NN)\n",
      "('what', 'WP')\n",
      "(NP island/NN)\n",
      "('is', 'VBZ')\n",
      "('it', 'PRP')\n",
      "('rainsford', 'JJ')\n",
      "('asked', 'VBD')\n"
     ]
    }
   ],
   "source": [
    "# How to Read the Grammar below:\n",
    "# Start with an optional (?) determiner ('DT')\n",
    "# Can have any number (*) of adjectives (JJ)\n",
    "# End with a noun (<NN>)\n",
    "grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "\n",
    "# Instantiate the chunk parser\n",
    "parser = nltk.RegexpParser(grammar)\n",
    "\n",
    "# Run it on our tagged text\n",
    "tree = parser.parse(mdg_tagged)\n",
    "\n",
    "# See some results\n",
    "for i in tree[0:20]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(NP a/DT large/JJ island/NN)\n"
     ]
    }
   ],
   "source": [
    "print(tree[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7722 3\n"
     ]
    }
   ],
   "source": [
    "print(len(tree), tree.height())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(), (0,), (1,), (2,), (3,), (3, 0), (3, 1), (4,), (5,), (6,), (6, 0), (6, 1), (6, 2), (7,), (8,), (8, 0), (9,), (10,), (11,), (12,)]\n"
     ]
    }
   ],
   "source": [
    "print(tree.treepositions()[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1593\n",
      "[Tree('NP', [('the', 'DT'), ('right', 'NN')]), Tree('NP', [('a', 'DT'), ('large', 'JJ'), ('island', 'NN')]), Tree('NP', [('whitney', 'NN')]), Tree('NP', [('a', 'DT'), ('mystery', 'NN')]), Tree('NP', [('island', 'NN')]), Tree('NP', [('ship', 'JJ'), ('trap', 'JJ'), ('island', 'NN')]), Tree('NP', [('whitney', 'NN')]), Tree('NP', [('a', 'DT'), ('suggestive', 'JJ'), ('name', 'NN')]), Tree('NP', [('isn', 'NN')]), Tree('NP', [('a', 'DT'), ('curious', 'JJ'), ('dread', 'NN')]), Tree('NP', [('the', 'DT'), ('place', 'NN')]), Tree('NP', [('some', 'DT'), ('superstition', 'NN')]), Tree('NP', [('rainsford', 'NN')]), Tree('NP', [('the', 'DT'), ('dank', 'JJ'), ('tropical', 'JJ'), ('night', 'NN')]), Tree('NP', [('thick', 'JJ'), ('warm', 'JJ'), ('blackness', 'NN')]), Tree('NP', [('the', 'DT'), ('yacht', 'NN')]), Tree('NP', [('whitney', 'NN')]), Tree('NP', [('a', 'DT'), ('laugh', 'NN')]), Tree('NP', [('i', 'NN')]), Tree('NP', [('a', 'DT'), ('moose', 'NN')])]\n"
     ]
    }
   ],
   "source": [
    "NPtrees = [subtree for subtree in tree if type(subtree) == nltk.Tree and subtree.label() == \"NP\"]\n",
    "\n",
    "print(len(NPtrees))\n",
    "print(NPtrees[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1593\n",
      "[[('the', 'DT'), ('right', 'NN')], [('a', 'DT'), ('large', 'JJ'), ('island', 'NN')], [('whitney', 'NN')], [('a', 'DT'), ('mystery', 'NN')], [('island', 'NN')], [('ship', 'JJ'), ('trap', 'JJ'), ('island', 'NN')], [('whitney', 'NN')], [('a', 'DT'), ('suggestive', 'JJ'), ('name', 'NN')], [('isn', 'NN')], [('a', 'DT'), ('curious', 'JJ'), ('dread', 'NN')], [('the', 'DT'), ('place', 'NN')], [('some', 'DT'), ('superstition', 'NN')], [('rainsford', 'NN')], [('the', 'DT'), ('dank', 'JJ'), ('tropical', 'JJ'), ('night', 'NN')], [('thick', 'JJ'), ('warm', 'JJ'), ('blackness', 'NN')], [('the', 'DT'), ('yacht', 'NN')], [('whitney', 'NN')], [('a', 'DT'), ('laugh', 'NN')], [('i', 'NN')], [('a', 'DT'), ('moose', 'NN')]]\n"
     ]
    }
   ],
   "source": [
    "NPleaves = [subtree.leaves() for subtree in tree if type(subtree) == nltk.Tree and subtree.label() == \"NP\"]\n",
    "\n",
    "print(len(NPleaves))\n",
    "print(NPleaves[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the right\n",
      "a large island\n",
      "whitney\n",
      "a mystery\n",
      "island\n",
      "ship trap island\n",
      "whitney\n",
      "a suggestive name\n",
      "isn\n",
      "a curious dread\n",
      "the place\n",
      "some superstition\n",
      "rainsford\n",
      "the dank tropical night\n",
      "thick warm blackness\n",
      "the yacht\n",
      "whitney\n",
      "a laugh\n",
      "i\n",
      "a moose\n"
     ]
    }
   ],
   "source": [
    "for a_list in NPleaves[0:20]:\n",
    "    np = [word for word,tag in a_list]\n",
    "    phrase = \" \".join(np)\n",
    "    print(phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entities\n",
    "\n",
    "You will need to download the named entity chunker first: `nltk.download(\"maxent_ne_chunker\")`.\n",
    "\n",
    "For more on the kinds of named entities: https://www.nltk.org/book/ch07.html#sec-ner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = nltk.ne_chunk(mdg_tagged, binary=True)\n",
    "\n",
    "def extract_ne(text):\n",
    "    # tokenize by word\n",
    "    words = nltk.tokenize.word_tokenize(text)\n",
    "    # apply part of speech tags to those words\n",
    "    tags = nltk.pos_tag(words)\n",
    "    # extract named entities based on those tags\n",
    "    # \"binary=True ==> named entities wonâ€™t be labeled by kind\n",
    "    tree = nltk.ne_chunk(tags, binary=True)\n",
    "    ne_set = set(\n",
    "        \" \".join(i[0] for i in t)\n",
    "        for t in tree\n",
    "        if hasattr(t, \"label\") and t.label() == \"NE\"\n",
    "    )\n",
    "    return ne_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Amazon', 'Rio', 'America', 'Rest', 'New York', 'Puritan', 'English', 'Caucasus', 'Island', 'American', 'Great White Czar', 'Uganda', 'Turkish', 'Malay', 'Rainsford', 'Suzette', 'Lazarus', 'Moscow', 'Russia', 'Africa', 'Ganges', 'General Zaroff', 'Malacca', 'Tibet', 'Purdey', 'Marcus Aurelius', 'Dusk', 'Caribbean', 'Mr. Rainsford', 'Caribbean Sea', 'Sleep', 'San Lucar', 'East Africa', 'God', 'Spanish', 'Pol Roger', 'Ship Trap', 'Sanger Rainsford', 'Chambertin', 'Chinese', 'Monte Carlo', 'Night', 'Crimea', 'Ivan', 'Madame Butterfly', 'Zaroff', 'Captain Nielsen', 'Toward', 'France', 'New York City', 'London', 'Rains', 'Whitney', 'Mr. Sanger Rainsford', 'French', 'Chablis', 'Veuve Cliquot', 'Russian', 'Great', 'Cossack', 'Paris'}\n"
     ]
    }
   ],
   "source": [
    "mdg_ne = extract_ne(mdg)\n",
    "print(mdg_ne)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "370",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

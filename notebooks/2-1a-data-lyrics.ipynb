{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "This notebook contains only 4 cells of code. You are of course free to delete all the documentation in between, but note the word I just used, <em>documentation</em>. Delete the current documentation, but be sure to create your own. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's suppose for a moment you are, like Braxton, interested in building a corpus of lyrics. You need to ask a couple of questions upfront:\n",
    "\n",
    "- What lyrics am I choosing and why?\n",
    "- Can I access those lyrics in the time I have available?\n",
    "\n",
    "While Braxton is interested in artists, you may be interested in lyrics that address certain topics. Given the way most lyrics sites are organized, artists is probably easier, but which artists and why? That is, at some point Braxton will probably need to articulate his choices. The conversation, either internal to him or between him and an undefined interlocutor (maybe me), might go something like this: \n",
    "\n",
    "**Q: \"Why'd you choose these artists?\"**  \n",
    "A: \"Because I like them.\"  \n",
    "**Q: \"Why do you like them?\"**  \n",
    "A: \"I think their songs are cool.\"  \n",
    "**Q: \"What makes their lyrics cool?\"**  \n",
    "A: \"I guess I need to figure this out.\"\n",
    "\n",
    "The bad news is that *Yes, yes you do*, but the good news is that you can make that the point of your exploration, but it's very important that you have this conversation early on and that you speculate as much as you can in your research notebook. Your speculations might include: \"I like the topics they sing about.\" Okay, what do you think those topics are? \"I like the way they rhyme things.\" Okay, what do you think those rhymes are. \n",
    "\n",
    "In each and every one of those speculations, you have a basis for beginning your analysis: topic modeling or grabbing the words at the end of lines and compiling them as pairs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, that's nice. But how do you get started? Well, I copied one of the artists Braxton named, **MF Doom**, and pasted \"MF Doom lyrics\" into a web search. (I think it was DuckDuckGo, but go with the search engine you like.) The first result was to a site called *[Genius](https://genius.com/artists/Mf-doom)*, but the UI was cluttered and my first impression was that there might be something better. The next result was for a site I recognize [AZlyrics](https://www.azlyrics.com/m/mfdoom.html), and when a list of albums and songs appeared on the first page with links to the songs, like [\"Meddle with Metal\"](https://www.azlyrics.com/lyrics/mfdoom/meddlewithmetal.html), I thought *this might work*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I have two URLs. The first gives me a list of songs:\n",
    "```\n",
    "https://www.azlyrics.com/lyrics/mfdoom/\n",
    "```\n",
    "And the second shows me what a song page looks like both in terms of the URL but also in terms of the HTML:\n",
    "```\n",
    "https://www.azlyrics.com/lyrics/mfdoom/meddlewithmetal.html\n",
    "```\n",
    "\n",
    "If this turns out to be relatively easy, I will need only `urllib` and `BeautifulSoup` to do this. \n",
    "\n",
    "Do I want anything else other than the song lyrics? Do I want to associate a song with a particular album? Do I want to include the album year? Given that I have multiple artists, do I want to associate an artist with each song? How am I going to create that metadata and how am I going to store it? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the first thing I want to do is load the libraries and see if I can establish a connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<!DOCTYPE html>\\r\\n<html lang=\"en\">\\r\\n<head>\\r\\n<meta charset=\"utf-8\">\\r\\n<meta http-equiv=\"X-UA-Compatible'\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# My starting web page\n",
    "myurl = \"https://www.azlyrics.com/m/mfdoom.html\"\n",
    "\n",
    "# How urllib expects:\n",
    "myconnection = urllib.request.urlopen(myurl)\n",
    "myhtml = myconnection.read()\n",
    "\n",
    "# Check to see that things work\n",
    "print(myhtml[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the connection established and HTML being returned. I need to find a way to get what I want from the page. I used my web browser to save the page's source and ran through the HTML until I got to the first song title:\n",
    "\n",
    "```html\n",
    "<!-- start of song list -->>\r\n",
    "<div id=\"listAlbum\"    >\r\n",
    "<div id=\"45679\" class=\"album\">album: <b>\"Operation: Doomsday\"</b> (19\n",
    "        99)<div><img src=\"/images/albums/456/d08d0c9c2e4eeb01a5166c594d2328fd.jp\n",
    "                 g\" class=\"album-image\" alt=\"MF Doom - Operation: Doomsday album cover\"\n",
    "         /></d\n",
    "    iv></div>\r\n",
    "<div class=\"listalbum-it\n",
    "    em\"><a href=\"/lyrics/mfdoom/thetimewefaceddoomskit.html\" target=\"_blank\">The Time We Faced Doom (S\n",
    "    kit)\n",
    "</a></\n",
    "```\n",
    "To some degree, some of the work of creating metadata is done for me, the song list is broken up by album and it looks like the DIVs are hierarchical ... let's strip everything else out and just look at the DIVs:\n",
    "```\n",
    "<div id=\"listAlbum\">\n",
    "    <div id=\"45679\" class=\"album\"> ALBUM NAME (DATE)</div>\n",
    "    <div class=\"listalbum-item\"> SONG </div>\n",
    "</div>\n",
    "```\n",
    "No, it's not hierarchical: the album names (and dates!) are simply at the top of the list of DIVs. *h*.iv>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`myhtml` is still active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.ResultSet'>\n",
      "<div class=\"listalbum-item\"><a href=\"/lyrics/mfdoom/thetimewefaceddoomskit.html\" target=\"_blank\">The Time We Faced Doom (Skit)</a></div>\n",
      "<div class=\"listalbum-item\"><a href=\"/lyrics/mfdoom/doomsday.html\" target=\"_blank\">Doomsday</a></div>\n"
     ]
    }
   ],
   "source": [
    "# Parse the divs with the song links\n",
    "mysoup = BeautifulSoup(myhtml, \"lxml\")\n",
    "mydivs = mysoup.find_all(class_=\"listalbum-item\")\n",
    "\n",
    "# Check work\n",
    "print(type(mydivs))\n",
    "for i in mydivs[0:2]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, I have something called an `element.ResultSet` which I can treat like a list an iterate over.\n",
    "\n",
    "The contents of each item in the set is the entire div. I could possibly use some regex, but I would also like to see if there's a way to do this in BeautifulSoup. I think I'll try iterating over the div and get the links out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/lyrics/mfdoom/thetimewefaceddoomskit.html', '/lyrics/mfdoom/doomsday.html']\n"
     ]
    }
   ],
   "source": [
    "# Empty list to hold the results\n",
    "links = []\n",
    "\n",
    "# Iterate over the list of DIVs\n",
    "for div in mydivs[0:2]:\n",
    "    the_link = div.find('a')['href']\n",
    "    links.append(the_link)\n",
    "\n",
    "# Check results\n",
    "print(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so now we have some piece of the URL we want to use in a list.\n",
    "\n",
    "Let's take a look at the URL we are trying to replicate:\n",
    "```\n",
    "https://www.azlyrics.com/lyrics/mfdoom/meddlewithmetal.html\n",
    "```\n",
    "\n",
    "It looks like all we need to do is prepend `https://www.azlyrics.com` to build the full URL. (Note that we have a slash already, so we don't need the trailing slash in our base URL.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Our List of Links to Download Files\n",
    "\n",
    "If you are comfortable downloading files in your current directory, then you can start doing that. If you want to see where you are, you can use one of the built-in \"magic\" commands, like `%pwd`, which should return something like:\n",
    "```\n",
    "'/Path/to/where/you/are'\n",
    "```\n",
    "You can then change to where you want to save the files, `%cd /Path/to/desired/directory`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our list of links all start at /lyrics\n",
    "# So we need to prepend the site URL\n",
    "baseURL = \"https://www.azlyrics.com\"\n",
    "\n",
    "# When we go to save the files, \n",
    "# we want to remove this part of the link string:\n",
    "myfilter = \"/lyrics/mfdoom/\"\n",
    "\n",
    "for link in links:\n",
    "    remotefile = urllib.request.urlopen(baseURL+link)\n",
    "    filename = link.replace(myfilter, '')\n",
    "    localfile = open(filename,'wb')\n",
    "    localfile.write(remotefile.read())\n",
    "    localfile.close()\n",
    "    remotefile.close()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
